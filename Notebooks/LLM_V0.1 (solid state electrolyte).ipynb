{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c9875-c40e-4a79-ba71-467f14ca9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from anthropic import Anthropic\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# API 초기화\n",
    "anthropic = Anthropic(api_key='api key 입력')\n",
    "openai.api_key = 'api key 입력'\n",
    "\n",
    "# 전역 데이터프레임 초기화\n",
    "columns = ['section', 'chemical composition', 'source', 'exp. calc', 'temperature', 'temp_unit', 'conductivity', 'unit', 'activation e', 'structure type', 'chemical family', 'mobile ion', 'Match Level', 'Reliability', 'Notes']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "property_name = 'Ionic Conductivity'\n",
    "\n",
    "definition = \"\"\"\n",
    "Ionic conductivity is a measure of a material's ability to conduct electric current through the movement of ions. It is a critical property in the study of electrolytes, solid-state ionic conductors, and other materials used in batteries, fuel cells, and other electrochemical devices.\n",
    "\n",
    "### Definition:\n",
    "Ionic conductivity (\\(\\sigma\\)) quantifies how well ions can move through a material under the influence of an electric field. It is defined as the electric current density (current per unit area) divided by the electric field strength. The higher the ionic conductivity, the more efficiently the material can transport ions.\n",
    "\n",
    "### Formula:\n",
    "\\[ \\sigma = \\frac{J}{E} \\]\n",
    "\n",
    "Where:\n",
    "- \\(\\sigma\\) is the ionic conductivity.\n",
    "- \\(J\\) is the current density (the current per unit area).\n",
    "- \\(E\\) is the electric field strength.\n",
    "\n",
    "### Unit:\n",
    "The unit of ionic conductivity is siemens per meter (S/m).\n",
    "\n",
    "In some contexts, especially for materials with low ionic conductivities, it might also be expressed in microsiemens per centimeter (\\(\\mu S/cm\\)) or millisiemens per centimeter (mS/cm). \n",
    "\n",
    "1 S/m = 10,000 \\(\\mu S/cm\\) = 10 mS/cm\n",
    "\"\"\"\n",
    "\n",
    "def extract_data(model, text, property_name, definition, doi):\n",
    "\n",
    "    prompt = f\"\"\"Analyze the uploaded section of scientific paper {text} on {property_name} with {definition} and create a table with the following columns, suitable for use in a deep learning regression model:\n",
    "    section | chemical composition | source | exp. calc | temperature | conductivity | unit | activation e | structure type | chemical family | mobile ion\n",
    "    Follow these guidelines:\n",
    "    \n",
    "    In the 'section' column, specify where the data comes from (e.g., 'Results and Discussion (Fig. 4)', 'Results and Discussion (text)', or both if applicable).\n",
    "    For 'source', use {doi}.\n",
    "    Indicate whether the data is experimental ('exp') or calculated ('calc').\n",
    "    Provide temperature values and specify the unit in 'temp_unit' (e.g., °C or K).\n",
    "    Give conductivity values in scientific notation when appropriate. \n",
    "    Specify the unit for conductivity.\n",
    "    Provide activation energy values.\n",
    "    For 'structure type', categorize according to the following options:\n",
    "    Rocksalt, Anti-Perovskite, Argyrodite, LISICON, Zircon, Garnet, Thio-LISICON, Perovskite, NASICON, Glass, Lysonite, Olivine, Phenakite, Glass-Ceramic, Other\n",
    "    If the structure doesn't fit these categories or if more detail is available, provide additional information (e.g., crystal system and space group).\n",
    "    Specify the chemical family (e.g., 'thiophosphate').\n",
    "    Identify the mobile ion (e.g., 'Li+').\n",
    "    Do not generate any content that cannot be verified from the text.\n",
    "    \n",
    "    When extracting data:\n",
    "    \n",
    "    Ensure all numerical values are provided in a consistent format suitable for machine learning models.\n",
    "    If a range of values is given, provide the mean value and note the range in a separate column or comment.\n",
    "    For categorical data (like structure type or chemical family), ensure consistent terminology is used across all entries.\n",
    "    If certain data points are missing, mark them as 'N/A' rather than leaving the cell empty.\n",
    "    If the paper provides multiple data points for the same material under different conditions, include all of them as separate entries.\n",
    "    \n",
    "    Include all relevant data points from the paper, even if they represent different experimental conditions for the same material. If any information is missing or unclear, indicate this in the table.\n",
    "    After creating the table, provide a brief summary of any key findings or notable aspects of the ionic conductivity data presented in the paper. Also, note any missing or unclear information in the paper regarding the requested data points.\n",
    "    Finally, suggest any additional features or data transformations that might be useful for a deep learning regression model focusing on predicting ionic conductivity based on material properties.\"\"\"\n",
    "    \n",
    "    if model == 'claude':\n",
    "        response = anthropic.messages.create(\n",
    "            model=\"claude 모델 입력\",\n",
    "            max_tokens=token 입력,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.content\n",
    "    elif model == 'gpt':\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt 모델 입력\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=token 입력\n",
    "        )\n",
    "        return response.choices[0].message['content']\n",
    "\n",
    "def compare_results(original_text, claude_result, gpt_result, property_name, definition, doi, preferred_model='gpt'):\n",
    "\n",
    "    prompt =  f\"\"\" Compare the data extracted by Claude and GPT from the same text. Present the final data table in the following format:\n",
    "    \n",
    "    | section | chemical composition | source | exp. calc | temperature | temp_unit | conductivity | unit | activation e | structure type | chemical family | mobile ion | Match Level | Reliability | Notes |\n",
    "    |---------|----------------------|--------|-----------|-------------|-----------|--------------|------|--------------|----------------|-----------------|------------|-------------|-------------|-------|\n",
    "    | {{section1}} | {{composition1}} | {doi} | {{exp_calc1}} | {{temperature1}} | {{temp_unit1}} | {{conductivity1}} | {{unit1}} | {{activation_e1}} | {{structure_type1}} | {{chemical_family1}} | {{mobile_ion1}} | {{Match Level}} | {{High/Medium/Low}} | {{Additional notes if needed}} |\n",
    "    | {{section2}} | {{composition2}} | {doi} | {{exp_calc2}} | {{temperature2}} | {{temp_unit2}} | {{conductivity2}} | {{unit2}} | {{activation_e2}} | {{structure_type2}} | {{chemical_family2}} | {{mobile_ion2}} | {{Match Level}} | {{High/Medium/Low}} | {{Additional notes if needed}} |\n",
    "    ...\n",
    "    \n",
    "    Original Text:\n",
    "    {original_text}\n",
    "    \n",
    "    Claude's Result:\n",
    "    {claude_result}\n",
    "    \n",
    "    GPT's Result:\n",
    "    {gpt_result}\n",
    "    \n",
    "    Instructions:\n",
    "    1. Carefully compare the original text with the results from both Claude and GPT to impove results by identifing missing data of {property_name} with {definition} and correcting inaccurate information.\n",
    "    2. If you find any data in the original text that neither model extracted, add it to the table and note this in the 'Notes' column.\n",
    "    3. Evaluate the match level using these criteria:\n",
    "       - Exact Match: The data from both models are identical in words and numbers\n",
    "       - Semantic Match: The expressions differ but convey the same information\n",
    "       - Partial Match: Some information matches, but there are differences\n",
    "       - Mismatch: The data from the two models are different or contradictory\n",
    "       - Missing: Data present in the original text but not extracted by either model\n",
    "    4. Determine the Final Value as follows:\n",
    "       - For Exact or Semantic Match: Choose either model's result\n",
    "       - For Partial Match: Select the more accurate or complete information\n",
    "       - For Mismatch: Use the result from {preferred_model.capitalize()}\n",
    "       - For Missing data: Use the information from the original text\n",
    "    5. Assess Reliability:\n",
    "       - High: Exact or Semantic Match, consistent with the original text\n",
    "       - Medium: Partial Match or only one model matches the original text\n",
    "       - Low: Mismatch, but {preferred_model.capitalize()}'s result is chosen\n",
    "       - Low: Missing data that had to be manually added from the original text\n",
    "    6. In the Notes column:\n",
    "       - Briefly mention any discrepancies, additional context, or reasoning behind the decision\n",
    "       - For missing data, indicate that it was not extracted by either model and had to be manually added\n",
    "    7. Create a row for each unique composition, including any that were missed by both models but present in the original text. Use 'No data' if information is genuinely missing from the original text.\n",
    "    8. Ensure that all numerical data extracted is accurate and correctly formatted for use in deep learning models.\n",
    "    9. For the 'structure type' column, categorize according to the following options:\n",
    "       Rocksalt, Anti-Perovskite, Argyrodite, LISICON, Zircon, Garnet, Thio-LISICON, Perovskite, NASICON, Glass, Lysonite, Olivine, Phenakite, Glass-Ceramic, Other\n",
    "       If the structure doesn't fit these categories or if more detail is available, provide additional information (e.g., crystal system and space group).\n",
    "    \"\"\"\n",
    "    \n",
    "    response = anthropic.messages.create(\n",
    "        model='claude 모델 입력',\n",
    "        max_tokens=token 입력,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.content[0].text\n",
    "\n",
    "def parse_table(table_string, source):\n",
    "    lines = table_string.strip().split('\\n')\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        if '|' in line:\n",
    "            columns_text = line.split('|')\n",
    "            if len(columns_text) >= 15:\n",
    "                new_col = [i.strip() for i in columns_text[1:16]]\n",
    "                new_col[2] = source  # 파일 이름을 source로 설정\n",
    "                data.append(new_col)\n",
    "    return data[2:]\n",
    "\n",
    "def update_dataframe(new_data):\n",
    "    global df\n",
    "    new_df = pd.DataFrame(new_data, columns=columns)\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    df = df[(df.conductivity != \"No data\") & (df.conductivity != \"N/A\")]\n",
    "    df.to_csv('추출된 파일(csv형태)', index=False)\n",
    "\n",
    "def process_section(section_text, section_name, property_name, definition, doi, preferred_model='gpt'):\n",
    "    claude_result = extract_data('claude', section_text, property_name, definition, doi)\n",
    "    gpt_result = extract_data('gpt', section_text, property_name, definition, doi)\n",
    "    compared_result = compare_results(section_text, claude_result, gpt_result, property_name, definition, doi, preferred_model)\n",
    "    parsed_result = parse_table(compared_result, doi)\n",
    "    update_dataframe(parsed_result)\n",
    "\n",
    "# 폴더 내 모든 텍스트 파일을 처리하는 함수 (날짜 폴더 추가)\n",
    "def process_all_files_in_folder(folder_path, property_name, definition, preferred_model='gpt'):\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.txt'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                # 각 파일을 처리\n",
    "                print(f\"Processing file: {filename}\")\n",
    "                process_section_from_file(file_path, property_name, definition, preferred_model)\n",
    "\n",
    "# 폴더 경로 설정 \n",
    "folder_path = \"경로 설정\"\n",
    "\n",
    "# 모든 파일 처리 함수 호출\n",
    "process_all_files_in_folder(folder_path, property_name, definition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
